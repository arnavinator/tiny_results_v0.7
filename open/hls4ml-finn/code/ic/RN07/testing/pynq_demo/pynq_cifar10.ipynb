{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from subprocess import call\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import numpy as np\n",
    "import keras\n",
    "from qkeras.utils import _add_supported_quantized_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPLOAD MODEL\n",
    "# path to model relative to downsample_tb.py\n",
    "model_file_path = \"./model_best.h5\"\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "model = keras.models.load_model(model_file_path, custom_objects = co)\n",
    "\n",
    "# # print model summary\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take any input img, do largest square center crop if not input not square,\n",
    "# and return a square img of dimsxdims\n",
    "def downsamp(img, dims):\n",
    "    smallest_dim = np.min(np.array([img.shape[0], img.shape[1]]))\n",
    "\n",
    "    # center crop relative to this image, so that we have square image\n",
    "    img_sq = img[int(img.shape[0]/2)-int(smallest_dim/2):int(img.shape[0]/2)+int(smallest_dim/2),\n",
    "                int(img.shape[1]/2)-int(smallest_dim/2):int(img.shape[1]/2)+int(smallest_dim/2),\n",
    "                :]\n",
    "\n",
    "    # interpolate to make image 32x32x3\n",
    "    res = cv2.resize(img_sq, dsize=(dims, dims), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon_mask = np.load(\"icon_mask.npy\")\n",
    "# plt.imshow(icon_mask[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f684b909bd8945708de7c6944320d280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, button_style='danger', description='Stop', icon='square', tooltip='Description')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN THE MODEL ITERATIVELY AND EVALUATE THE FRAME USING NEURAL NET\n",
    "# PRESS STOP TO PREVENT THE MODEL FROM CONTINUING\n",
    "# MODEL PREDICTION SHOWN AS AN ICON ON THE TOP LEFT OF THE SCREEN\n",
    "\n",
    "# Stop button\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# Display function\n",
    "# ================\n",
    "def view(button):\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    i = 0\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        \n",
    "        '''\n",
    "        send the image to the accelerator here\n",
    "        '''\n",
    "        res = downsamp(frame, 32)\n",
    "        \n",
    "        # convert to input ready for neural net\n",
    "        X_dtest = np.ascontiguousarray(res, dtype=np.float32)  # doesn't change shape, just turns every element to float instead of int\n",
    "        X_dtest = X_dtest/256.\n",
    "\n",
    "        # have model predict the image\n",
    "        y_pred = model.predict(np.array([X_dtest]))\n",
    "        \n",
    "        # print \n",
    "\n",
    "        mask = icon_mask[np.argmax(y_pred[0])]\n",
    "        \n",
    "        # print(\"frame size is :\", frame.shape)\n",
    "        # print(\"mask size is : \", mask.size)\n",
    "        frame = cv2.subtract(frame, mask)\n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "\n",
    "            \n",
    "# Run\n",
    "# ================\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
