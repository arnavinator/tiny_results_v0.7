{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from subprocess import call\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import qkeras\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.datasets import cifar10\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Dense, Activation, Flatten, BatchNormalization\n",
    "# from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, Add\n",
    "# from tensorflow.keras.regularizers import l1_l2\n",
    "# from qkeras.qlayers import QDense, QActivation\n",
    "# from qkeras.qconvolutional import QConv2D\n",
    "# from qkeras.qconv2d_batchnorm import QConv2DBatchnorm\n",
    "# from qkeras.qpooling import QAveragePooling2D\n",
    "# from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPLOAD MODEL\n",
    "# path to model relative to downsample_tb.py\n",
    "model_file_path = \"../training/trained_model/model_best.h5\"\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "model = keras.models.load_model(model_file_path, custom_objects = co)\n",
    "\n",
    "# # print model summary\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take any input img, do largest square center crop if not input not square,\n",
    "# and return a square img of dimsxdims\n",
    "def downsamp(img, dims):\n",
    "    smallest_dim = np.min(np.array([img.shape[0], img.shape[1]]))\n",
    "\n",
    "    # center crop relative to this image, so that we have square image\n",
    "    img_sq = img[int(img.shape[0]/2)-int(smallest_dim/2):int(img.shape[0]/2)+int(smallest_dim/2),\n",
    "                int(img.shape[1]/2)-int(smallest_dim/2):int(img.shape[1]/2)+int(smallest_dim/2),\n",
    "                :]\n",
    "\n",
    "    # interpolate to make image 32x32x3\n",
    "    res = cv2.resize(img_sq, dsize=(dims, dims), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_images_from_folder(folder):\n",
    "#     images = []\n",
    "#     for filename in os.listdir(folder):\n",
    "#         print(filename)   # use this to create y_dtest!!!!\n",
    "#         img = cv2.imread(os.path.join(folder,filename))\n",
    "#         if img is not None:\n",
    "#             images.append(img)\n",
    "#     return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Icon Images Uploaded: \")\n",
    "# X_dtest_1 = load_images_from_folder(\"./icon_lib\")\n",
    "# icon_ims = []\n",
    "# for elem in X_dtest_1:\n",
    "#     icon_ims.append(downsamp(elem, 128))\n",
    "\n",
    "# icon_ims = np.array(icon_ims)\n",
    "# np.save(\"icon_ims.npy\", icon_ims)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icon_ims_1 = np.load('icon_ims.npy')\n",
    "# plt.imshow(icon_ims_1[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plane_img_original = cv2.imread('./airplane_vector.png')\n",
    "# # dims = 128\n",
    "# # plane_downsamp = downsamp(plane_img_original, dims)\n",
    "\n",
    "# icon_mask = []\n",
    "\n",
    "# for elem in icon_ims_1:\n",
    "#     plane_img = 255 - elem\n",
    "#     mask = np.ones((480,640, 3), np.uint8)\n",
    "#     mask[0:128, -128:] = plane_img[0:128,0:128,:]\n",
    "#     icon_mask.append(mask)\n",
    "\n",
    "# icon_mask = np.array(icon_mask)\n",
    "# np.save(\"icon_mask.npy\", icon_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24fdd8c3d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "icon_mask = np.load(\"icon_mask.npy\")\n",
    "plt.imshow(icon_mask[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17cfc3a7a3c4344a5a19873f9866564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, button_style='danger', description='Stop', icon='square', tooltip='Description')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN THE MODEL ITERATIVELY AND EVALUATE THE FRAME USING NEURAL NET\n",
    "# PRESS STOP TO PREVENT THE MODEL FROM CONTINUING\n",
    "# MODEL PREDICTION SHOWN AS AN ICON ON THE TOP LEFT OF THE SCREEN\n",
    "\n",
    "# Stop button\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# Display function\n",
    "# ================\n",
    "def view(button):\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    i = 0\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        \n",
    "        '''\n",
    "        send the image to the accelerator here\n",
    "        '''\n",
    "        res = downsamp(frame, 32)\n",
    "        \n",
    "        # convert to input ready for neural net\n",
    "        X_dtest = np.ascontiguousarray(res, dtype=np.float32)  # doesn't change shape, just turns every element to float instead of int\n",
    "        X_dtest = X_dtest/256.\n",
    "\n",
    "        # have model predict the image\n",
    "        y_pred = model.predict(np.array([X_dtest]))\n",
    "        \n",
    "        # print \n",
    "\n",
    "        mask = icon_mask[np.argmax(y_pred[0])]\n",
    "        \n",
    "        # print(\"frame size is :\", frame.shape)\n",
    "        # print(\"mask size is : \", mask.size)\n",
    "        frame = cv2.subtract(frame, mask)\n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "\n",
    "            \n",
    "# Run\n",
    "# ================\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
